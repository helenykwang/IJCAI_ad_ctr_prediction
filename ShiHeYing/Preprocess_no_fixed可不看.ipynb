{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 查看每列缺失值的数量和比率函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def missing(combine):\n",
    "    mark=0\n",
    "    for data in combine:\n",
    "        dic={}\n",
    "        dic['Alength']=len(data)\n",
    "        for i in data.isnull().any()[data.isnull().any()].index:\n",
    "            dic[i]=[str(len(data[data[i].isnull()]))+'   '+str(round(100*len(data[data[i].isnull()])/len(data),3))+'%']\n",
    "        if mark==100:\n",
    "            nantest=pd.DataFrame(dic)\n",
    "            break\n",
    "        else:\n",
    "            nantrain=pd.DataFrame(dic)\n",
    "        mark=100\n",
    "    return nantrain,nantest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 删除instance_id重复的列并且组合train和test到一起进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_category_property列缺失的行数： 4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#['predict_category_property', 'item_category_list', 'item_property_list']\n",
    "train=pd.read_csv(r'D:\\Data\\IJCAI\\train.csv',na_values=-1)\n",
    "test=pd.read_csv(r'D:\\Data\\IJCAI\\test.csv',na_values=-1)\n",
    "train.drop_duplicates(inplace=True)\n",
    "train=train.sort_values(by=['instance_id'])\n",
    "train.index=np.arange(len(train))\n",
    "for ind in train.index:                     #删除完全重复的记录并对只有instance_id重复的记录重新赋值\n",
    "    if ind<(len(train)-1):\n",
    "        if train.loc[ind,'instance_id']==train.loc[(ind+1),'instance_id']:\n",
    "            train.loc[(ind+1),'instance_id']=train.loc[ind,'instance_id']+1\n",
    "print('predict_category_property列缺失的行数：',len(train[train['predict_category_property'].isnull()]))\n",
    "train.drop(list(train[train['predict_category_property'].isnull()].index),axis=0,inplace=True)\n",
    "\n",
    "train['timestamp']=pd.to_datetime(train['context_timestamp'].copy(),unit='s')\n",
    "train['day']=train['timestamp'].dt.day\n",
    "test['timestamp']=pd.to_datetime(test['context_timestamp'].copy(),unit='s')\n",
    "test['day']=test['timestamp'].dt.day\n",
    "\n",
    "is_trade=train['is_trade']                                  #将train和test组合到一起进行处理\n",
    "train.drop(['is_trade'],axis=1,inplace=True)\n",
    "train['is_trade']=is_trade\n",
    "test['is_trade']=1000\n",
    "train=pd.concat([train,test],axis=0)\n",
    "train.index=np.arange(len(train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前一天商品的转换率和前两天的转换率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train['num_conversion']=0\n",
    "train['num_conversiontd']=0\n",
    "for day in set(train['day'].values):\n",
    "    if day<18:\n",
    "        continue\n",
    "    else:\n",
    "        for u in set(train[train['day']==day]['item_id'].values):\n",
    "            if u in train[train['day']==(day-1)]['item_id'].values:\n",
    "                train.loc[train[(train['item_id']==u)&(train['day']==day)].index,'num_conversion']=\\\n",
    "                len(train[(train['item_id']==u)&(train['day']==(day-1))&(train['is_trade']==1)])/len(train[(train['item_id']==u)&(train['day']==(day-1))])\n",
    "            if day<19:\n",
    "                continue\n",
    "            else:\n",
    "                if u in train[(train['day']==(day-1))|(train['day']==(day-2))]['item_id'].values:\n",
    "                    train.loc[train[(train['item_id']==u)&(train['day']==day)].index,'num_conversiontd']=\\\n",
    "                    (len(train[(train['item_id']==u)&(train['day']==(day-1))&(train['is_trade']==1)])+\\\n",
    "                     len(train[(train['item_id']==u)&(train['day']==(day-2))&(train['is_trade']==1)]))/(len(train[(train['item_id']==u)&(train['day']==(day-1))])+\\\n",
    "                                                                                                    len(train[(train['item_id']==u)&(train['day']==(day-2))]))\n",
    "print('train has done！')\n",
    "train.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\train_conversion.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提取每天用户点击数，商品被点击数，各个时间间隔,并将train和test重新分开，test按照最开始的顺序排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv(r'D:\\Data\\IJCAI\\no_fixed\\train_conversion.csv',na_values=-1)\n",
    "train=train.sort_values(by=['day','user_id'])                               #同一天同一个用户的点击广告的次数——--用户的搜索次数和点击次数\n",
    "h=train.groupby(by=['day','user_id']).count()\n",
    "lis=[]\n",
    "for i,j in h.index:\n",
    "    lis.extend([h.loc[i].loc[j]['instance_id']]*h.loc[i].loc[j]['instance_id'])\n",
    "train['num_click']=lis\n",
    "\n",
    "train=train.sort_values(by=['day','item_id'])                              #同一天同一件商品被搜索点击次数-----商品的被搜索次数和受欢迎程度\n",
    "h=train.groupby(by=['day','item_id']).count()\n",
    "lis=[]\n",
    "for i,j in h.index:\n",
    "    lis.extend([h.loc[i].loc[j]['instance_id']]*h.loc[i].loc[j]['instance_id'])\n",
    "train['num_show']=lis\n",
    "    \n",
    "train=train.sort_values(by=['item_id','context_timestamp'])                 #同一件商品被搜索点击的时间间隔\n",
    "train.index=np.arange(len(train))\n",
    "lis=[]\n",
    "for val in set(train['item_id'].values):\n",
    "    lis.append(train[train['item_id']==val].index[-1])\n",
    "temp=train['context_timestamp'].diff()\n",
    "for i in lis:\n",
    "    temp.loc[i+1]=0\n",
    "temp.loc[0]=0\n",
    "train['item_time_diff']=temp\n",
    "\n",
    "train=train.sort_values(by=['day','item_id','context_timestamp'])          #同一天同一件商品的被搜索点击的时间间隔\n",
    "train.index=np.arange(len(train))\n",
    "lis=[]\n",
    "for d in [17,18,19,20,21,22,23,24,25]:\n",
    "    for val in set(train[train['day']==d]['item_id'].values):\n",
    "        lis.append(train[(train['item_id']==val)&(train['day']==d)].index[-1])\n",
    "temp=train['context_timestamp'].diff()\n",
    "for i in lis:\n",
    "    temp.loc[i+1]=0\n",
    "temp.loc[0]=0\n",
    "train['day_item_diff']=temp\n",
    "    \n",
    "train=train.sort_values(by=['day','user_id','context_timestamp'])          #同一天相同用户的不同商品点击时间间隔\n",
    "train.index=np.arange(len(train))\n",
    "lis=[]\n",
    "for d in [17,18,19,20,21,22,23,24,25]:\n",
    "    for val in set(train[train['day']==d]['user_id'].values):\n",
    "        lis.append(train[(train['user_id']==val)&(train['day']==d)].index[-1])\n",
    "temp=train['context_timestamp'].diff()\n",
    "for i in lis:\n",
    "    temp.loc[i+1]=0\n",
    "temp.loc[0]=0\n",
    "train['day_user_diff']=temp\n",
    "\n",
    "train.index=np.arange(len(train))\n",
    "train['num_item_day']=0\n",
    "for val in set(train['item_id'].values):               #商品被推荐并被点击的天数\n",
    "    train.loc[list(train[train['item_id']==val].index),'num_item_day']=len(set(train[train['item_id']==val]['day'].values))\n",
    "    \n",
    "train['num_user_day']=0\n",
    "for val in set(train['user_id'].values):               #用户点击广告的天数\n",
    "    train.loc[list(train[train['user_id']==val].index),'num_user_day']=len(set(train[train['user_id']==val]['day'].values))\n",
    "##########################################################################################################################################\n",
    "test=train[train['is_trade']==1000]\n",
    "train.drop(list(train[train['is_trade']==1000].index),axis=0,inplace=True)\n",
    "train.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\train_pre1.csv',index=False)\n",
    "print('Train has being Done!')\n",
    "\n",
    "test.drop(['is_trade'],axis=1,inplace=True)          #test按照最初的顺序排序好提交结果\n",
    "test.index=np.arange(len(test))\n",
    "print('length of test is：',len(test))\n",
    "new=pd.read_csv(r'D:\\Data\\IJCAI\\test.csv')\n",
    "print('length of new is：',len(new))\n",
    "print('Is set(new[instance_id].values)==set(test[instance_id].values)',set(new['instance_id'].values)==set(test['instance_id'].values))\n",
    "lis=[]\n",
    "for i in new.index:\n",
    "    lis.extend(list(test[test['instance_id']==new.loc[i,'instance_id']].index))\n",
    "test=test.loc[lis]\n",
    "test.index=np.arange(len(test))\n",
    "test.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\test_pre1.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对缺失值进行填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alength</th>\n",
       "      <th>item_brand_id</th>\n",
       "      <th>item_city_id</th>\n",
       "      <th>item_sales_level</th>\n",
       "      <th>shop_review_positive_rate</th>\n",
       "      <th>shop_score_delivery</th>\n",
       "      <th>shop_score_description</th>\n",
       "      <th>shop_score_service</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender_id</th>\n",
       "      <th>user_occupation_id</th>\n",
       "      <th>user_star_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>478107</td>\n",
       "      <td>473   0.099%</td>\n",
       "      <td>277   0.058%</td>\n",
       "      <td>913   0.191%</td>\n",
       "      <td>7   0.001%</td>\n",
       "      <td>59   0.012%</td>\n",
       "      <td>59   0.012%</td>\n",
       "      <td>59   0.012%</td>\n",
       "      <td>964   0.202%</td>\n",
       "      <td>12902   2.699%</td>\n",
       "      <td>964   0.202%</td>\n",
       "      <td>964   0.202%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alength item_brand_id  item_city_id item_sales_level  \\\n",
       "0   478107  473   0.099%  277   0.058%     913   0.191%   \n",
       "\n",
       "  shop_review_positive_rate shop_score_delivery shop_score_description  \\\n",
       "0                7   0.001%         59   0.012%            59   0.012%   \n",
       "\n",
       "  shop_score_service user_age_level  user_gender_id user_occupation_id  \\\n",
       "0        59   0.012%   964   0.202%  12902   2.699%       964   0.202%   \n",
       "\n",
       "  user_star_level  \n",
       "0    964   0.202%  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "train=pd.read_csv(r'D:\\Data\\IJCAI\\no_fixed\\train_pre1.csv',na_values=-1)\n",
    "test=pd.read_csv(r'D:\\Data\\IJCAI\\no_fixed\\test_pre1.csv',na_values=-1)\n",
    "combine=[train,test]\n",
    "nantrain,nantest=missing(combine)\n",
    "nantrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alength</th>\n",
       "      <th>item_brand_id</th>\n",
       "      <th>item_city_id</th>\n",
       "      <th>item_sales_level</th>\n",
       "      <th>shop_score_delivery</th>\n",
       "      <th>shop_score_description</th>\n",
       "      <th>shop_score_service</th>\n",
       "      <th>user_age_level</th>\n",
       "      <th>user_gender_id</th>\n",
       "      <th>user_occupation_id</th>\n",
       "      <th>user_star_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18371</td>\n",
       "      <td>18   0.098%</td>\n",
       "      <td>6   0.033%</td>\n",
       "      <td>35   0.191%</td>\n",
       "      <td>1   0.005%</td>\n",
       "      <td>1   0.005%</td>\n",
       "      <td>1   0.005%</td>\n",
       "      <td>18   0.098%</td>\n",
       "      <td>469   2.553%</td>\n",
       "      <td>18   0.098%</td>\n",
       "      <td>18   0.098%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alength item_brand_id item_city_id item_sales_level shop_score_delivery  \\\n",
       "0    18371   18   0.098%   6   0.033%      35   0.191%          1   0.005%   \n",
       "\n",
       "  shop_score_description shop_score_service user_age_level user_gender_id  \\\n",
       "0             1   0.005%         1   0.005%    18   0.098%   469   2.553%   \n",
       "\n",
       "  user_occupation_id user_star_level  \n",
       "0        18   0.098%     18   0.098%  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nantest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 2000 3000 4000 5000 6000 7000 8000 9000 10000 11000 12000 Done!\n"
     ]
    }
   ],
   "source": [
    "# corr=train[['instance_id', 'item_id', 'item_brand_id', 'item_city_id', 'item_price_level', 'item_sales_level', 'item_collected_level', \\\n",
    "#             'item_pv_level', 'user_id', 'user_gender_id', 'user_age_level', 'user_occupation_id','user_star_level', 'context_id', \\\n",
    "#             'context_timestamp', 'context_page_id','shop_id', 'shop_review_num_level', 'shop_review_positive_rate', 'shop_star_level', \\\n",
    "#             'shop_score_service', 'shop_score_delivery', 'shop_score_description', 'timestamp', 'day', 'is_trade', 'num_conversion', \\\n",
    "#             'num_conversiontd', 'num_click', 'num_show', 'item_time_diff', 'day_item_diff', 'day_user_diff']].corr()\n",
    "# corr[corr['shop_review_positive_rate']>0.1]['shop_review_positive_rate'].sort_values(ascending=False).head(6)#shop_score_description\n",
    "train.index=np.arange(len(train))\n",
    "test.index=np.arange(len(test))\n",
    "for ind in train[train['shop_review_positive_rate'].isnull()].index:\n",
    "    item_price_level=train.loc[ind,'item_price_level']\n",
    "    train.loc[ind,'shop_review_positive_rate']=train[train['item_price_level']==item_price_level]['shop_review_positive_rate'].median()\n",
    "# corr[corr['shop_score_delivery']>0.1]['shop_score_delivery'].sort_values(ascending=False).head(6)\n",
    "#['shop_score_delivery','shop_score_description','shop_score_service']这四列是同时缺失的需要一起填充\n",
    "#train[train['user_age_level'].isnull()][['is_trade','user_age_level','user_occupation_id','user_star_level']]\n",
    "h=['shop_score_delivery','shop_score_description','shop_score_service']\n",
    "combine=[train,test]\n",
    "for data in combine:\n",
    "    for hj in h:\n",
    "        for ind in data[data[hj].isnull()].index:\n",
    "            shop_review_positive_rate=data.loc[ind,'shop_review_positive_rate']\n",
    "            item_price_level=data.loc[ind,'item_price_level']\n",
    "            temp=data[(data['shop_review_positive_rate']==shop_review_positive_rate)&(data['item_price_level']==item_price_level)]\n",
    "            if temp['shop_score_service'].isnull().any():\n",
    "                data.loc[ind,'shop_score_service']=data[data['item_price_level']==item_price_level]['shop_score_service'].median()\n",
    "            else:\n",
    "                data.loc[ind,'shop_score_service']=train.median()\n",
    "            if temp['shop_score_delivery'].isnull().any():\n",
    "                data.loc[ind,'shop_score_delivery']=data[data['item_price_level']==item_price_level]['shop_score_delivery'].median()\n",
    "            else:\n",
    "                data.loc[ind,'shop_score_delivery']=round(train['shop_score_delivery'].median(),6)\n",
    "            if temp['shop_score_description'].isnull().any():\n",
    "                data.loc[ind,'shop_score_description']=data[data['item_price_level']==item_price_level]['shop_score_description'].median()\n",
    "            else:\n",
    "                data.loc[ind,'shop_score_description']=train['shop_score_description'].median()\n",
    "# corr[corr['user_age_level']>0.1]['user_age_level'].sort_values(ascending=False).head(6)\n",
    "#['is_trade','user_age_level','user_occupation_id','user_star_level']这三列是同时缺失的需要一起填充\n",
    "combine=[train,test]\n",
    "h=['user_age_level','user_occupation_id','user_star_level']\n",
    "for data in combine:\n",
    "    for hj in h:\n",
    "        for ind in data[data[hj].isnull()].index:\n",
    "            shop_score_description=data.loc[ind,'shop_score_description']\n",
    "            item_price_level=data.loc[ind,'item_price_level']\n",
    "            temp=data[(data['shop_score_description']==shop_score_description)&(data['item_price_level']==item_price_level)]\n",
    "            if temp['user_age_level'].isnull().any():\n",
    "                data.loc[ind,'user_age_level']=data[data['item_price_level']==item_price_level]['user_age_level'].median()\n",
    "            else:\n",
    "                data.loc[ind,'user_age_level']=temp['user_age_level'].median()\n",
    "            if temp['user_occupation_id'].isnull().any():\n",
    "                if (data[data['shop_score_description']==shop_score_description]['user_occupation_id'].isnull().any())\\\n",
    "                and (data[data['item_price_level']==item_price_level]['user_occupation_id'].isnull().any()):\n",
    "                    data.loc[ind,'user_occupation_id']=data.loc[ind+6,'user_occupation_id']\n",
    "                elif (data[data['shop_score_description']==shop_score_description]['user_occupation_id'].isnull().any())\\\n",
    "                and (not data[data['item_price_level']==item_price_level]['user_occupation_id'].isnull().any()):\n",
    "                    data.loc[ind,'user_occupation_id']=data[data['item_price_level']==item_price_level]['user_occupation_id'].value_counts().index[0]\n",
    "                else:\n",
    "                    data.loc[ind,'user_occupation_id']=data[data['shop_score_description']==shop_score_description]['user_occupation_id'].value_counts().index[0]\n",
    "            else:\n",
    "                data.loc[ind,'user_occupation_id']=temp['user_occupation_id'].value_counts().index[0]\n",
    "            if temp['user_star_level'].isnull().any():\n",
    "                data.loc[ind,'user_star_level']=data[data['shop_score_description']==shop_score_description]['user_star_level'].median()\n",
    "            else:\n",
    "                data.loc[ind,'user_star_level']=temp['user_star_level'].median()\n",
    "    for ind in data[data['user_star_level'].isnull()].index:\n",
    "        data.loc[ind,'user_star_level']=data.loc[ind-6,'user_star_level']\n",
    "    for ind in data[data['user_age_level'].isnull()].index:\n",
    "        data.loc[ind,'user_age_level']=data.loc[ind-6,'user_age_level']\n",
    "# corr[corr['item_brand_id']>0.06]['item_brand_id'].sort_values(ascending=False).head(6)\n",
    "combine=[train,test]\n",
    "for data in combine:\n",
    "    for ind in data[data['item_brand_id'].isnull()].index:\n",
    "        shop_id=data.loc[ind,'shop_id']\n",
    "        temp=data[data['shop_id']==shop_id]\n",
    "        if len(temp['item_brand_id'].isnull())==len(temp):\n",
    "            data.loc[ind,'item_brand_id']=data.loc[ind-1,'item_brand_id']\n",
    "        else:\n",
    "            data.loc[ind,'item_brand_id']=temp['item_brand_id'].value_counts().index[0]\n",
    "# corr[corr['item_city_id']>0.006]['item_city_id'].sort_values(ascending=False).head(6)\n",
    "combine=[train,test]\n",
    "for data in combine:\n",
    "    for ind in data[data['item_city_id'].isnull()].index:\n",
    "        item_price_level=data.loc[ind,'item_price_level']\n",
    "        temp=data[data['item_price_level']==item_price_level]\n",
    "        data.loc[ind,'item_city_id']=temp['item_city_id'].value_counts().index[0]\n",
    "# corr[corr['item_sales_level']>0.1]['item_sales_level'].sort_values(ascending=False).head(6)\n",
    "combine=[train,test]\n",
    "for data in combine:\n",
    "    for ind in data[data['item_sales_level'].isnull()].index:\n",
    "        item_collected_level=data.loc[ind,'item_collected_level']\n",
    "        item_pv_level=data.loc[ind,'item_pv_level']\n",
    "        temp=data[(data['item_collected_level']==item_collected_level)&(data['item_pv_level']==item_pv_level)]\n",
    "        if temp['item_sales_level'].isnull().any():\n",
    "            data.loc[ind,'item_sales_level']=data[data['item_collected_level']==item_collected_level]['item_sales_level'].median()\n",
    "        else:\n",
    "            data.loc[ind,'item_sales_level']=temp['item_sales_level'].median()\n",
    "# corr[corr['user_gender_id']>0.01]['user_gender_id'].sort_values(ascending=False).head(6)\n",
    "combine=[train,test]\n",
    "for data in combine:\n",
    "    count=0\n",
    "    for ind in data[data['user_gender_id'].isnull()].index:\n",
    "        count+=1\n",
    "        user_age_level=data.loc[ind,'user_age_level']\n",
    "        temp=data[data['user_age_level']==user_age_level]\n",
    "        if (len(temp)==0) and (len(data[data['user_age_level']==user_age_level]['user_gender_id'])!=0):\n",
    "            data.loc[ind,'user_gender_id']=data[data['user_age_level']==user_age_level]['user_gender_id'].value_counts().index[0]\n",
    "        elif temp['user_gender_id'].isnull().any():\n",
    "            data.loc[ind,'user_gender_id']=0\n",
    "        else:\n",
    "            data.loc[ind,'user_gender_id']=temp['user_gender_id'].value_counts().index[0]\n",
    "        if count%1000==0:\n",
    "            print(count,end=' ')\n",
    "train.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\train_misspre.csv',index=False)\n",
    "test.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\test_misspre.csv',index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 广告商品和预测属性和类目数量和比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 20000 30000 40000 50000 60000 70000 80000 90000 100000 110000 120000 130000 140000 150000 160000 170000 180000 190000 200000 210000 220000 230000 240000 250000 260000 270000 280000 290000 300000 310000 320000 330000 340000 350000 360000 370000 380000 390000 400000 410000 420000 430000 440000 450000 460000 470000 10000 50647.33700275421\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "s=time.time()\n",
    "combine=[train,test]\n",
    "for data in combine:\n",
    "    data['com_pre_cate']=0\n",
    "    data['com_pre_pro']=0\n",
    "    data['com_pre_cateprob']=0\n",
    "    data['com_pre_proprob']=0\n",
    "    data['num_true_property']=0\n",
    "    data['num_pred_category']=0\n",
    "    data['num_pred_property']=0\n",
    "    for ind in data.index:\n",
    "        Category=data.loc[ind,'item_category_list'].split(';')\n",
    "        Property=data.loc[ind,'item_property_list'].split(';')\n",
    "        liscate=[]\n",
    "        lispro=[]\n",
    "        for i in data.loc[ind,'predict_category_property'].split(';'):\n",
    "            liscate.append(i.split(':')[0])\n",
    "            lispro.extend(i.split(':')[1].split(','))\n",
    "        while '1000' in Category:\n",
    "            Category.remove('1000')\n",
    "        while '-1' in lispro:\n",
    "            lispro.remove('-1')\n",
    "        comcate=len(set(Category)&set(liscate))\n",
    "        compro=len(set(Property)&set(lispro))\n",
    "        data.loc[ind,['com_pre_cate','com_pre_pro','com_pre_cateprob','com_pre_proprob','num_true_property',\\\n",
    "                      'num_pred_category','num_pred_property']]=[comcate,compro,comcate/math.sqrt(len(Category)*len(liscate)+1),\\\n",
    "                                                                 compro/math.sqrt(len(Property)*len(lispro)+1),len(Property),\\\n",
    "                                                                 len(liscate),len(lispro)]\n",
    "        if (ind %10000==0) and (ind!=0):\n",
    "            print(ind,end=' ')\n",
    "e=time.time()\n",
    "print(e-s)\n",
    "train.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\train_mispret.csv',index=False)\n",
    "test.to_csv(r'D:\\Data\\IJCAI\\no_fixed\\test_mispret.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
